benchmark:
  benchmark:
    name: nq
    path: data/sample_nq_10.jsonl
    key_map:
      q_ls: question
      gt_ls: golden_answers
    shuffle: false
    seed: 42
    limit: -1
retriever:
  model_name_or_path: openbmb/MiniCPM-Embedding-Light
  backend_configs:
    infinity:
      bettertransformer: false
      pooling_method: auto
      model_warmup: false
      trust_remote_code: true
    sentence_transformers:
      trust_remote_code: true
      sentence_transformers_encode:
        normalize_embeddings: false
        encode_chunk_size: 256
        q_prompt_name: query
        psg_prompt_name: document
        psg_task: null
        q_task: null
    openai:
      model_name:  text-embedding-v4
      base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
      api_key: sk-5230a3
    bm25:
      lang: en
      save_path: index/bm25
  batch_size: 16
  corpus_path: data/corpus_example.jsonl
  gpu_ids: '1'
  is_multimodal: false
  backend: openai
  index_backend: faiss
  index_backend_configs:
    faiss:
      index_use_gpu: true
      index_chunk_size: 10000
      index_path: index/index.index
    milvus:
      uri: tcp://127.0.0.1:29901
      token: null
      id_field_name: id
      vector_field_name: vector
      text_field_name: contents
      id_max_length: 64
      text_max_length: 60000
      metric_type: IP
      index_params:
        index_type: AUTOINDEX
        metric_type: IP
      search_params:
        metric_type: IP
        params: {}
      index_chunk_size: 1000
  is_demo: false
  collection_name: my_data
  top_k: 5
  query_instruction: ''
generation:
  backend_configs:
    vllm:
      model_name_or_path: openbmb/MiniCPM4-8B
      gpu_ids: 2,3
      gpu_memory_utilization: 0.9
      dtype: auto
      trust_remote_code: true
    openai:
      model_name: qwen-plus
      base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
      api_key: sk-5230a376
      concurrency: 8
      retries: 3
      base_delay: 1.0
    hf:
      model_name_or_path: openbmb/MiniCPM4-8B
      gpu_ids: 2,3
      trust_remote_code: true
      batch_size: 8
  sampling_params:
    temperature: 0.7
    top_p: 0.8
    max_tokens: 2048
  extra_params:
    chat_template_kwargs:
      enable_thinking: false
  backend: openai
  system_prompt: '你现在是一个基于检索增强生成技术的系统，请根据检索到的内容，准确的回答用户的问题，请一定记住使用中文回答问题'
custom: {}
prompt:
  template: prompt/md_qa_rag_citation.jinja
